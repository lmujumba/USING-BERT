{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USING-BERT FOR TWEETS CLASSIFICATION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b2856e5f79c4bacb6bfa6e42b29da6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20df6bb306ee41fe86948aae367064f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8b04cf5b0db4952873d5a2a00f51c79",
              "IPY_MODEL_d33232e1981d40bd825440285ea593d1"
            ]
          }
        },
        "20df6bb306ee41fe86948aae367064f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8b04cf5b0db4952873d5a2a00f51c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f765b71880f54451aaca85caffbb4214",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_815cbd853fe84c319e38d94fa2aab2e2"
          }
        },
        "d33232e1981d40bd825440285ea593d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0672b509b9234e00b0d8de982be1abd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 801kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_771f5a463b8346aa913b859e54aef190"
          }
        },
        "f765b71880f54451aaca85caffbb4214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "815cbd853fe84c319e38d94fa2aab2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0672b509b9234e00b0d8de982be1abd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "771f5a463b8346aa913b859e54aef190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d44909b05b04344be9eca0f8aadd6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0be9605c4c840399bdf52414db80975",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a1a2a77c8634a18b14ac47c8874e639",
              "IPY_MODEL_12c341e427a3473892fa9c28075d8760"
            ]
          }
        },
        "d0be9605c4c840399bdf52414db80975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a1a2a77c8634a18b14ac47c8874e639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5a2bf2a134b4b4395a1a98bf03b25e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5b91c2bcdae4e6eb154d38db3a4562d"
          }
        },
        "12c341e427a3473892fa9c28075d8760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d08fe136b014cb38624827d1bab3720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 723B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8959e9a91854fcea5b1307ae3a5fa41"
          }
        },
        "b5a2bf2a134b4b4395a1a98bf03b25e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5b91c2bcdae4e6eb154d38db3a4562d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d08fe136b014cb38624827d1bab3720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8959e9a91854fcea5b1307ae3a5fa41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0eda3f86ca414c57a067795c0a28f43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ce20337e72b4718bb5b7a413e1f3bd2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_593e5e72caf94931b09127b644079b60",
              "IPY_MODEL_0e20deb196ec418aa950a37835b3444b"
            ]
          }
        },
        "5ce20337e72b4718bb5b7a413e1f3bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "593e5e72caf94931b09127b644079b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0837502e222a428aa9032eca999a3540",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5d8917aaf364c56a953315b7903a36c"
          }
        },
        "0e20deb196ec418aa950a37835b3444b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b2bab916bdc40dc9fd811a809213f58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [01:42&lt;00:00, 2.60MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc9b282c7ac54daeb4d14623505b8009"
          }
        },
        "0837502e222a428aa9032eca999a3540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5d8917aaf364c56a953315b7903a36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b2bab916bdc40dc9fd811a809213f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc9b282c7ac54daeb4d14623505b8009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy9Z0YQ0DJ7J"
      },
      "source": [
        "Using BERT ON A TWITTER DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luIni8i3ZA65",
        "outputId": "b070baec-bb69-4fe4-bcef-a303f114ac42"
      },
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvoCpHdqZF6E",
        "outputId": "53f45977-8a57-4cc9-c568-e332151a9541"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7tN3obvZR7Q",
        "outputId": "1da3551f-8970-4622-e2d9-36496b61004a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 7.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=a3187ce9308498089d0153b7208295eb0d4303b6b2aac9674bb6b79174a44939\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4pOPr5tYird"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jan 30 02:59:27 2020\n",
        "\n",
        "@author: Zohainus\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string \n",
        "import re\n",
        "import numpy as np\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
        "from nltk.corpus import stopwords\n",
        "import unicodedata\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from string import punctuation\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.pipeline import Pipeline,FeatureUnion\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix,classification_report,accuracy_score\n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import make_union,make_pipeline\n",
        "from sklearn.feature_selection import SelectFromModel,VarianceThreshold,  SelectPercentile,SelectKBest, f_classif,chi2\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "from textblob import TextBlob\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import *\n",
        "import csv\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhSBYFDDB2A4",
        "outputId": "201f6939-ff4a-4885-d6d7-177737635049"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS2XW9HBY1Sz"
      },
      "source": [
        "#Read Dataset\n",
        "#To see full tweet\n",
        "pd.set_option(\"display.max_colwidth\", 100)\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/engtweets.csv\",encoding=\"latin-1\", names = [\"label\",\"Tweets\"]).astype(str)\n",
        "#new_data = pd.read_csv(\"\",encoding=\"latin-1\", names = [\"label\",\"Tweets\"]).astype(str)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_mRnzqEX0pD"
      },
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "         # Lowercase\n",
        "        text = text.lower()\n",
        "        \n",
        "        words_seperated_by_space = text.split(\" \")\n",
        "        words_seperated_by_space = [k.replace(\"\\\\xa0\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\xc2\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\n\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\r\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\xc8\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\x9b\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\x99\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\xc4\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\x83\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\"99%er\\\"\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\x99\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"2x80\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"cxf3\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"2x80\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"u0111\", \" \") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"cixe2x80m\", \" \") for k in words_seperated_by_space]\n",
        "\n",
        "        words_seperated_by_space = [k.replace(\"don't\", \"dont\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"won't\", \"wont\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"can't\", \"cant\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"i\\'m\", \"i am\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"ain't\", \"is not\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\'ll\", \"will\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\'t\", \"not\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\'ve\", \"have\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"'s\", \"is\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\'re\", \"are\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\'d\", \"would\") for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [k.replace(\"\\\\ \\\\ \", \" \") for k in words_seperated_by_space]\n",
        "\n",
        "        words_seperated_by_space = [re.sub(\" u \", \"you\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"[!]+\", \"!\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('[?]+', \"?\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('[.]+', \".\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('[\\\\\\]+', \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('[\\']+', \".\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(haha)+\", \"haha\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(l(ol)+)\", \"lol \", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(bw(a)+h)\", \"bwah\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(bwa(h)+)\", \"bwah\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(bwa(h)+)\", \"bwah\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"<[a-z]*>\", \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"[*****]+\", \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub(\"(xe2x80x(9|a6))\", \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('_', \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('-', \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('<>', \"\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('g(rrr)+', \"grr\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('u(mmm)+|u(mm)+', \"umm\", str(k)) for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('@[A-Za-z0-9]+',' ',str(k))for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('https?://[A-Za-z0-9./]+',' ',str(k))for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('#[A-Za-z0-9]+',' ',str(k))for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('\\W', ' ', str(k))for k in words_seperated_by_space]\n",
        "        words_seperated_by_space = [re.sub('\\s+', ' ', str(k))for k in words_seperated_by_space]\n",
        "        text = ' '.join(words_seperated_by_space)\n",
        "        # Remove HTML tags\n",
        "        text = re.sub(r'<[^>]*>', '', text)\n",
        "        # Remove twitter handlers, hashtags symbols and URLs\n",
        "        text = re.sub(r'@[\\w_-]+', ' ', text)\n",
        "        text = re.sub('https?://[^ ]+', ' ', text)\n",
        "        text = re.sub('#', '', text)\n",
        "        text = re.sub('rt', '', text)\n",
        "        # Expand contractions\n",
        "        text = re.sub(r\"i'm\", \" i am \", text)\n",
        "        text = re.sub(r\" im \", \" i am \", text)\n",
        "        text = re.sub(r\"\\: p\", \"\", text)\n",
        "        text = re.sub(r\" ive \", \" i have \", text)\n",
        "        text = re.sub(r\" he's \", \" he is \", text)\n",
        "        text = re.sub(r\" she's \", \" she is \", text)\n",
        "        text = re.sub(r\" that's \", \" that is \", text)\n",
        "        text = re.sub(r\" what's \", \" what is \", text)\n",
        "        text = re.sub(r\" where's \", \" where is \", text)\n",
        "        text = re.sub(r\" haven't \", \" have not \", text)\n",
        "        text = re.sub(r\" ur \", \" you are \", text)\n",
        "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "        text = re.sub(r\"\\'re\", \" are\", text)\n",
        "        text = re.sub(r\"\\'d\", \" would\", text)\n",
        "        text = re.sub(r\" won't \", \" will not \", text)\n",
        "        text = re.sub(r\" wouldn't \", \" would not \", text)\n",
        "        text = re.sub(r\" can't \", \" cannot \", text)\n",
        "        text = re.sub(r\" cannot \", \" cannot \", text)\n",
        "        text = re.sub(r\" don't \", \" do not \", text)\n",
        "        text = re.sub(r\" didn't \", \" did not \", text)\n",
        "        text = re.sub(r\" doesn't \", \" does not \", text)\n",
        "        text = re.sub(r\" isn't \", \" is not \", text)\n",
        "        text = re.sub(r\" it's \", \" it is \", text)\n",
        "        text = re.sub(r\" who's \", \" who is \", text)\n",
        "        text = re.sub(r\" there's \", \" there is \", text)\n",
        "        text = re.sub(r\" weren't \", \" were not \", text)\n",
        "        text = re.sub(r\" okay \", \" o\", text)\n",
        "        text = re.sub(r\" you're \", \" you are \", text)\n",
        "        text = re.sub(r\" c'mon \", \" come on \", text)\n",
        "        text = re.sub(r\"in'\", \"ing\", text)\n",
        "        text = re.sub(r\"\\'s\", \" s\", text)\n",
        "        # Remove ponctuation and special chars except ! and ?\n",
        "        text = re.sub('[^a-zA-Z?!\\s]', ' ', text)\n",
        "        # Lemmatize\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        sentence = []\n",
        "        for word in text.split(' '):\n",
        "            sentence.append(lemmatizer.lemmatize(word))\n",
        "        # Rebuild sentences\n",
        "        text = ' '.join(sentence)\n",
        "        # Remove stopwords\n",
        "        stopWords = set(stopwords.words('english'))\n",
        "        sentence = []\n",
        "        for word in text.split(' '):\n",
        "            if word not in stopWords:\n",
        "                sentence.append(word)\n",
        "        # Rebuild sentences\n",
        "        text = ' '.join(sentence)\n",
        "        return text\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpnt-ELiZiXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7840af6-37ab-4425-ea74-3e0cb95790c1"
      },
      "source": [
        "# caling function\n",
        "dataset['Tweets_clean'] = dataset['Tweets'].apply(preprocess_text)\n",
        "dataset['Tweets_clean'].values.reshape(1,-1)\n",
        "print (f'G = {len(dataset[dataset[\"label\"]==\"G\"])}')\n",
        "print (f'NG = {len(dataset[dataset[\"label\"]==\"NG\"])}')\n",
        "#new_data['Tweets_clean'] = new_data['Tweets'].apply(preprocess_text)\n",
        "#print(new_data['Tweets_clean'])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G = 576\n",
            "NG = 433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-VrQ3R3Qe6K"
      },
      "source": [
        "Loading the Pre-trained BERT model\n",
        "\n",
        "distilBERT model - a version of BERT that is smaller, but much faster and requiring a lot less memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "2b2856e5f79c4bacb6bfa6e42b29da6b",
            "20df6bb306ee41fe86948aae367064f9",
            "f8b04cf5b0db4952873d5a2a00f51c79",
            "d33232e1981d40bd825440285ea593d1",
            "f765b71880f54451aaca85caffbb4214",
            "815cbd853fe84c319e38d94fa2aab2e2",
            "0672b509b9234e00b0d8de982be1abd4",
            "771f5a463b8346aa913b859e54aef190",
            "1d44909b05b04344be9eca0f8aadd6e7",
            "d0be9605c4c840399bdf52414db80975",
            "3a1a2a77c8634a18b14ac47c8874e639",
            "12c341e427a3473892fa9c28075d8760",
            "b5a2bf2a134b4b4395a1a98bf03b25e8",
            "e5b91c2bcdae4e6eb154d38db3a4562d",
            "4d08fe136b014cb38624827d1bab3720",
            "e8959e9a91854fcea5b1307ae3a5fa41",
            "0eda3f86ca414c57a067795c0a28f43b",
            "5ce20337e72b4718bb5b7a413e1f3bd2",
            "593e5e72caf94931b09127b644079b60",
            "0e20deb196ec418aa950a37835b3444b",
            "0837502e222a428aa9032eca999a3540",
            "f5d8917aaf364c56a953315b7903a36c",
            "8b2bab916bdc40dc9fd811a809213f58",
            "cc9b282c7ac54daeb4d14623505b8009"
          ]
        },
        "id": "dVPf0VVezaun",
        "outputId": "d82ec25f-e870-4c52-8ea1-1e895ff971dc"
      },
      "source": [
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For DistilBERT:its less heavy than Bert\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "#For  BERT--THIS TAKES A LOT OF TIME ON MY MACHINE SO NOT RECOMMENDED\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b2856e5f79c4bacb6bfa6e42b29da6b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d44909b05b04344be9eca0f8aadd6e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eda3f86ca414c57a067795c0a28f43b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CkTv0VYRcIv"
      },
      "source": [
        "#to tokenize using bert\n",
        "tokenized = dataset['Tweets_clean'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzmi4nGe0B_B"
      },
      "source": [
        "After tokenization, tokenized is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sGh0RuEN0Hz"
      },
      "source": [
        "#Padding the values\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLoUNyRt0Dyi",
        "outputId": "44fe8779-b19e-4692-9f17-c09e3915215d"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1010, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dckn5oFKN8fe"
      },
      "source": [
        "TFIDFVECTORIZATION NOT NEEDED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydDGGbjb1Vi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "339ad142-6d43-4900-cf20-0e18049c19e9"
      },
      "source": [
        "\"\"\"\n",
        "# TFidfVectorization\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "X = tfidf_vect.fit_transform(dataset['Tweets_clean'])\n",
        "\n",
        "print(X.shape)\n",
        "X1 = tfidf_vect.transform(new_data['Tweets_clean']).toarray()\n",
        "\n",
        "print(X1.shape)\n",
        "y = dataset['label']\n",
        "print(dataset.groupby(['label']).size())\n",
        "skf = StratifiedKFold(n_splits=10, random_state=18, shuffle=True)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "  \"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# TFidfVectorization\\ntfidf_vect = TfidfVectorizer()\\nX = tfidf_vect.fit_transform(dataset['Tweets_clean'])\\n\\nprint(X.shape)\\nX1 = tfidf_vect.transform(new_data['Tweets_clean']).toarray()\\n\\nprint(X1.shape)\\ny = dataset['label']\\nprint(dataset.groupby(['label']).size())\\nskf = StratifiedKFold(n_splits=10, random_state=18, shuffle=True)\\nfor train_index, test_index in skf.split(X, y):\\n    X_train, X_test = X[train_index], X[test_index]\\n  \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d856e5-3fac-48fd-e05a-67cde26cbd76"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1010, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4fA_Nh1F1s"
      },
      "source": [
        "The model() function runs our sentences through BERT. The results of the processing will be returned into last_hidden_states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz"
      },
      "source": [
        "import torch\n",
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs"
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-"
      },
      "source": [
        "The labels indicating which sentence is positive(G) and negative(NG) now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datAset into a training set and testing set \n",
        "\n",
        "Rename dataset to batch_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFJJ9fHzTZgN"
      },
      "source": [
        "X=features\n",
        "y = dataset['label']"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZebyRfL1QsfE"
      },
      "source": [
        "Staritified Kfold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTXEypmPSkA2"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "skf = KFold(n_splits = 10, shuffle = True, random_state = 18)\n",
        "#result = next(skf.split(dataset), None)\n",
        "#print (result)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "#train = dataset.iloc[result[0]]\n",
        "#test =  dataset.iloc[result[1]]\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvl_yUR7QB7b"
      },
      "source": [
        "LOAD MODELS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8UN4lkDZjPw"
      },
      "source": [
        "# Comparison of Classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import *\n",
        "from xgboost import XGBClassifier\n",
        "models = {\n",
        "            'LinearSVC':LinearSVC(),\n",
        "            #'SVC':SVC(C = 10, gamma= 0.4, kernel = 'sigmoid') ,\n",
        "            #'SVC':SVC(C = 10, gamma= 0.2, kernel = 'linear') ,\n",
        "            #'SVC':SVC(C = 10, gamma= 0.4, kernel = 'poly') ,\n",
        "            'LogisticRegression':LogisticRegression(penalty='l2', dual=False, tol=0.0001, C= 0.5, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, verbose=5, warm_start=False, n_jobs=-1),\n",
        "            'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
        "            'RandomForestClassifier':RandomForestClassifier(),\n",
        "            'GradientBoostClassifier':GradientBoostingClassifier(),\n",
        "            'KNN':KNeighborsClassifier(),\n",
        "            'NB':GaussianNB(),\n",
        "            'AdaBoost':AdaBoostClassifier(),\n",
        "            'BaggingClassifier':BaggingClassifier(),\n",
        "            'XGBClassifier':XGBClassifier(),\n",
        "            'LightGBM':LGBMClassifier()\n",
        "            }\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ4MQ5nXT9eE",
        "outputId": "33ed8990-7a8b-4579-de54-9ad67cd32933"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "with open('NewFinalReport.txt','w') as file:\n",
        "  file.writelines\n",
        "  for name, model in models.items():\n",
        "      clf = model\n",
        "      clf.fit(X_train, y_train)\n",
        "      y_pred = clf.predict(X_test)\n",
        "      #y_pred = clf.predict(X1)\n",
        "      #print(y_pred)\n",
        "    \n",
        "      print('Accuracy score of ' + name , accuracy_score(y_test,y_pred))\n",
        "\n",
        "      f.writelines('%s,%s\\n,%s\\n'%('Accuracy score of '+ name , accuracy_score(y_test, y_pred),classification_report(y_test, y_pred)))\n",
        "\n",
        "      print('Accuracy score of '+ name , accuracy_score(y_test, y_pred),'\\n',classification_report(y_test, y_pred))\n",
        "      \n",
        "      print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of LinearSVC 0.7524752475247525\n",
            "Accuracy score of LinearSVC 0.7524752475247525 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.70      0.81      0.75        47\n",
            "          NG       0.81      0.70      0.75        54\n",
            "\n",
            "    accuracy                           0.75       101\n",
            "   macro avg       0.76      0.76      0.75       101\n",
            "weighted avg       0.76      0.75      0.75       101\n",
            "\n",
            "[[38  9]\n",
            " [16 38]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of LogisticRegression 0.7425742574257426\n",
            "Accuracy score of LogisticRegression 0.7425742574257426 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.70      0.79      0.74        47\n",
            "          NG       0.79      0.70      0.75        54\n",
            "\n",
            "    accuracy                           0.74       101\n",
            "   macro avg       0.74      0.75      0.74       101\n",
            "weighted avg       0.75      0.74      0.74       101\n",
            "\n",
            "[[37 10]\n",
            " [16 38]]\n",
            "Accuracy score of DecisionTreeClassifier 0.6732673267326733\n",
            "Accuracy score of DecisionTreeClassifier 0.6732673267326733 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.64      0.68      0.66        47\n",
            "          NG       0.72      0.67      0.69        54\n",
            "       label       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.67       101\n",
            "   macro avg       0.45      0.45      0.45       101\n",
            "weighted avg       0.68      0.67      0.68       101\n",
            "\n",
            "[[32 14  1]\n",
            " [18 36  0]\n",
            " [ 0  0  0]]\n",
            "Accuracy score of RandomForestClassifier 0.6732673267326733\n",
            "Accuracy score of RandomForestClassifier 0.6732673267326733 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.62      0.77      0.69        47\n",
            "          NG       0.74      0.59      0.66        54\n",
            "\n",
            "    accuracy                           0.67       101\n",
            "   macro avg       0.68      0.68      0.67       101\n",
            "weighted avg       0.69      0.67      0.67       101\n",
            "\n",
            "[[36 11]\n",
            " [22 32]]\n",
            "Accuracy score of GradientBoostClassifier 0.7425742574257426\n",
            "Accuracy score of GradientBoostClassifier 0.7425742574257426 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.68      0.83      0.75        47\n",
            "          NG       0.82      0.67      0.73        54\n",
            "\n",
            "    accuracy                           0.74       101\n",
            "   macro avg       0.75      0.75      0.74       101\n",
            "weighted avg       0.76      0.74      0.74       101\n",
            "\n",
            "[[39  8]\n",
            " [18 36]]\n",
            "Accuracy score of KNN 0.6534653465346535\n",
            "Accuracy score of KNN 0.6534653465346535 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.59      0.81      0.68        47\n",
            "          NG       0.76      0.52      0.62        54\n",
            "\n",
            "    accuracy                           0.65       101\n",
            "   macro avg       0.68      0.66      0.65       101\n",
            "weighted avg       0.68      0.65      0.65       101\n",
            "\n",
            "[[38  9]\n",
            " [26 28]]\n",
            "Accuracy score of NB 0.6138613861386139\n",
            "Accuracy score of NB 0.6138613861386139 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.58      0.60      0.59        47\n",
            "          NG       0.64      0.63      0.64        54\n",
            "\n",
            "    accuracy                           0.61       101\n",
            "   macro avg       0.61      0.61      0.61       101\n",
            "weighted avg       0.61      0.61      0.61       101\n",
            "\n",
            "[[28 19]\n",
            " [20 34]]\n",
            "Accuracy score of AdaBoost 0.5742574257425742\n",
            "Accuracy score of AdaBoost 0.5742574257425742 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.53      0.83      0.64        47\n",
            "          NG       0.70      0.35      0.47        54\n",
            "\n",
            "    accuracy                           0.57       101\n",
            "   macro avg       0.62      0.59      0.56       101\n",
            "weighted avg       0.62      0.57      0.55       101\n",
            "\n",
            "[[39  8]\n",
            " [35 19]]\n",
            "Accuracy score of BaggingClassifier 0.7227722772277227\n",
            "Accuracy score of BaggingClassifier 0.7227722772277227 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.69      0.72      0.71        47\n",
            "          NG       0.75      0.72      0.74        54\n",
            "\n",
            "    accuracy                           0.72       101\n",
            "   macro avg       0.72      0.72      0.72       101\n",
            "weighted avg       0.72      0.72      0.72       101\n",
            "\n",
            "[[34 13]\n",
            " [15 39]]\n",
            "Accuracy score of XGBClassifier 0.7326732673267327\n",
            "Accuracy score of XGBClassifier 0.7326732673267327 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.67      0.83      0.74        47\n",
            "          NG       0.81      0.65      0.72        54\n",
            "\n",
            "    accuracy                           0.73       101\n",
            "   macro avg       0.74      0.74      0.73       101\n",
            "weighted avg       0.75      0.73      0.73       101\n",
            "\n",
            "[[39  8]\n",
            " [19 35]]\n",
            "Accuracy score of LightGBM 0.7425742574257426\n",
            "Accuracy score of LightGBM 0.7425742574257426 \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           G       0.68      0.83      0.75        47\n",
            "          NG       0.82      0.67      0.73        54\n",
            "\n",
            "    accuracy                           0.74       101\n",
            "   macro avg       0.75      0.75      0.74       101\n",
            "weighted avg       0.76      0.74      0.74       101\n",
            "\n",
            "[[39  8]\n",
            " [18 36]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddAqbkoU6PP9"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af7BkU-SSihA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNaYgRzaQ2-"
      },
      "source": [
        "# it is the code when i use another dataset to train the model. ok    \n",
        "\n",
        "question1 = y_pred  #question 1 data\n",
        "question2 = new_data['Tweets_clean'] #question 2 data\n",
        "df = pd.DataFrame(columns=[\"label\", \"Tweets\"])\n",
        "df[\"label\"] = question1\n",
        "df[\"Tweets\"] = question2\n",
        "df.to_csv(\"C:\\\\Users\\\\Zohainus\\\\Desktop\\\\newdata\\\\april2019.csv\",index=False)\n",
        "new_data_op = pd.read_csv(\"C:\\\\Users\\\\Zohainus\\\\Desktop\\\\newdata\\\\april2019.csv\",encoding=\"latin-1\", names = [\"label\",\"Tweets\"],delimiter=',').astype(str)\n",
        "#How many labels in dataset\n",
        "print (f'G = {len(new_data_op[new_data_op[\"label\"]==\"G\"])}')\n",
        "print (f'NG = {len(new_data_op[new_data_op[\"label\"]==\"NG\"])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kug1ekweYPjD"
      },
      "source": [
        "Exploring the dataset\n",
        "# Sahpe of data\n",
        "print (f\"Input data has {len(dataset)} rows, {len(dataset.columns)}columns\")\n",
        "#How many labels in dataset\n",
        "print (f'G = {len(new_data[new_data[\"label\"]==\"G\"])}')\n",
        "print (f'NG = {len(new_data[new_data[\"label\"]==\"NG\"])}')\n",
        "# Missing values in any row, ignore those\n",
        "print (f\"Number of missing labels = {dataset ['label'].isnull().sum() }\")\n",
        "print (f\"Number of missing labels = {dataset ['Tweets'].isnull().sum() }\")\n",
        "\n",
        "'''\n",
        "'''\n",
        "# Confusion Matrix of LinearSvc\n",
        "#import modules\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "#ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "model = LinearSVC()\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "#Construct the Confusion Matrix\n",
        "label = ['G', 'NG']\n",
        "cm = confusion_matrix(y_test, pred, label)\n",
        "print(cm)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + label)\n",
        "ax.set_yticklabels([''] + label)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}